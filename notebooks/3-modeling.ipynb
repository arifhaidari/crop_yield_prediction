{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year</th>\n",
       "      <th>Yield</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>Pesticides</th>\n",
       "      <th>avg_precipitation</th>\n",
       "      <th>group</th>\n",
       "      <th>yield_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cassava</td>\n",
       "      <td>1990</td>\n",
       "      <td>41177</td>\n",
       "      <td>24.12</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cassava</td>\n",
       "      <td>1991</td>\n",
       "      <td>40295</td>\n",
       "      <td>24.02</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cassava</td>\n",
       "      <td>1992</td>\n",
       "      <td>42295</td>\n",
       "      <td>23.96</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cassava</td>\n",
       "      <td>1993</td>\n",
       "      <td>42295</td>\n",
       "      <td>24.15</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Cassava</td>\n",
       "      <td>1994</td>\n",
       "      <td>58596</td>\n",
       "      <td>24.04</td>\n",
       "      <td>25.5</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Area     Item  Year  Yield  avg_temp  Pesticides  avg_precipitation  \\\n",
       "0  Angola  Cassava  1990  41177     24.12        64.0               1010   \n",
       "1  Angola  Cassava  1991  40295     24.02        79.0               1010   \n",
       "2  Angola  Cassava  1992  42295     23.96        23.0               1010   \n",
       "3  Angola  Cassava  1993  42295     24.15       169.0               1010   \n",
       "4  Angola  Cassava  1994  58596     24.04        25.5               1010   \n",
       "\n",
       "   group  yield_normalized  \n",
       "0      0          0.087702  \n",
       "1      0          0.085821  \n",
       "2      0          0.090086  \n",
       "3      0          0.090086  \n",
       "4      0          0.124847  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Cassava: 73691.38333381955\n",
      "Item_Maize: -51269.26243665961\n",
      "Item_Plantains and others: 36321.717322162825\n",
      "Item_Potatoes: 110373.3098962319\n",
      "Item_Rice, paddy: -42439.490406804936\n",
      "Item_Sorghum: -65222.84743043374\n",
      "Item_Soybeans: -70384.68987578891\n",
      "Item_Sweet potatoes: 37017.510523288845\n",
      "Item_Wheat: -60960.25673407328\n",
      "Item_Yams: 32872.6258082854\n",
      "avg_temp: -1881.8009102492074\n",
      "Pesticides: 0.11303158925875323\n",
      "avg_precipitation: -7.151592588650146\n",
      "Intercept: 127913.37725739882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the features and target variable\n",
    "features = ['avg_temp', 'Pesticides', 'avg_precipitation', 'Item']\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Create a column transformer to apply OneHotEncoder to the 'Item' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['Item'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and the LinearRegression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the feature names after one-hot encoding\n",
    "ohe = preprocessor.named_transformers_['onehot']\n",
    "feature_names = ohe.get_feature_names_out(input_features=['Item'])\n",
    "other_features = ['avg_temp', 'Pesticides', 'avg_precipitation']\n",
    "all_features = list(feature_names) + other_features\n",
    "\n",
    "# Get the coefficients for the features from the model\n",
    "coefficients = pipeline.named_steps['model'].coef_\n",
    "\n",
    "# Print out the features with their coefficients\n",
    "feature_coefficients = dict(zip(all_features, coefficients))\n",
    "for feature, coef in feature_coefficients.items():\n",
    "    print(f'{feature}: {coef}')\n",
    "\n",
    "# Print out the intercept\n",
    "intercept = pipeline.named_steps['model'].intercept_\n",
    "print(f'Intercept: {intercept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - R-squared: 0.7117227321699506\n",
      "Mean Squared Error: 1979179822.1676779\n",
      "Root Mean Squared Error: 44487.97390495186\n",
      "Mean Absolute Error: 27297.063750659217\n",
      "Testing Data - R-squared: 0.6835850746893448\n",
      "Mean Squared Error: 2234526332.996134\n",
      "Root Mean Squared Error: 47270.77673358175\n",
      "Mean Absolute Error: 28285.205242170956\n"
     ]
    }
   ],
   "source": [
    "# This time with polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "categorical_features = ['Item']\n",
    "numerical_features = ['avg_temp', 'Pesticides', 'avg_precipitation']\n",
    "features = numerical_features + categorical_features\n",
    "X = df[features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a column transformer to apply OneHotEncoder to the 'Item' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define polynomial features with interaction only\n",
    "poly_features = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "# Create a pipeline with the preprocessor, polynomial features, and a linear regression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('polynomial_features', poly_features),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train =  np.sqrt(mse_train)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Predict and evaluate on testing data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test =  np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results for training data\n",
    "print(f'Training Data - R-squared: {r2_train}')\n",
    "print(f'Mean Squared Error: {mse_train}')\n",
    "print(f'Root Mean Squared Error: {rmse_train}')\n",
    "print(f'Mean Absolute Error: {mae_train}')\n",
    "\n",
    "# Print the results for testing data\n",
    "print(f'Testing Data - R-squared: {r2_test}')\n",
    "print(f'Mean Squared Error: {mse_test}')\n",
    "print(f'Root Mean Squared Error: {rmse_test}')\n",
    "print(f'Mean Absolute Error: {mae_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - R-squared: 0.6461088192621558\n",
      "Mean Squared Error: 2429654927.1181436\n",
      "Root Mean Squared Error: 49291.52997339547\n",
      "Mean Absolute Error: 30832.38565185251\n",
      "test data start here \n",
      "\n",
      "Testing Data - R-squared: 0.6199842590081104\n",
      "Mean Squared Error: 2683676123.5764027\n",
      "Root Mean Squared Error: 51804.2095159882\n",
      "Mean Absolute Error: 31714.73449654645\n"
     ]
    }
   ],
   "source": [
    "# experiment with linear regression without applying the \n",
    "\n",
    "# Create a column transformer to apply OneHotEncoder to the 'Item' column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['Item'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and the LinearRegression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train =  np.sqrt(mse_train)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Predict and evaluate on testing data\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test =  np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results for training data\n",
    "print(f'Training Data - R-squared: {r2_train}')\n",
    "print(f'Mean Squared Error: {mse_train}')\n",
    "print(f'Root Mean Squared Error: {rmse_train}')\n",
    "print(f'Mean Absolute Error: {mae_train}')\n",
    "\n",
    "print('test data start here \\n')\n",
    "# Print the results for testing data\n",
    "print(f'Testing Data - R-squared: {r2_test}')\n",
    "print(f'Mean Squared Error: {mse_test}')\n",
    "print(f'Root Mean Squared Error: {rmse_test}')\n",
    "print(f'Mean Absolute Error: {mae_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: As you can see the result is better with polynomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_features = ['Item', 'Area']\n",
    "numerical_features = ['Pesticides', 'avg_temp', 'avg_precipitation']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = df[categorical_features + numerical_features]\n",
    "y = df['Yield']\n",
    "\n",
    "# Splitting data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "std_scaler = StandardScaler(with_mean=False)\n",
    "X_train_scale = std_scaler.fit_transform(X_train)\n",
    "# Scale test data for evaluation\n",
    "X_test_scale = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training R-squared: 0.9966919170441194, Testing R-squared: 0.9800000535520749\n",
      "Random Forest - Training MAE: 1797.9047465646977, Testing MAE: 4578.1348319488925\n",
      "Random Forest - Training MSE: 22711783.990528207, Testing MSE: 141239882.8927693\n",
      "Random Forest - Training RMSE: 4765.688196947866, Testing RMSE: 11884.438686482812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest (Supervised learning)\n",
    "rf = RandomForestRegressor(max_depth=None, min_samples_split=2, n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "rf_train_score = r2_score(y_train, y_train_pred)\n",
    "rf_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "rf_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "rf_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "rf_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "rf_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rf_train_rmse = np.sqrt(rf_train_mse)\n",
    "rf_test_rmse = np.sqrt(rf_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Random Forest - Training R-squared: {rf_train_score}, Testing R-squared: {rf_test_score}\")\n",
    "print(f\"Random Forest - Training MAE: {rf_train_mae}, Testing MAE: {rf_test_mae}\")\n",
    "print(f\"Random Forest - Training MSE: {rf_train_mse}, Testing MSE: {rf_test_mse}\")\n",
    "print(f\"Random Forest - Training RMSE: {rf_train_rmse}, Testing RMSE: {rf_test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Training R-squared: 0.9994296884108363, Testing R-squared: 0.9812698999654889\n",
      "Gradient Boosting - Training MAE: 833.0961013549303, Testing MAE: 4334.7053504787555\n",
      "Gradient Boosting - Training MSE: 3915498.43009692, Testing MSE: 132272210.94477764\n",
      "Gradient Boosting - Training RMSE: 1978.7618426927784, Testing RMSE: 11500.965652708368\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=300, learning_rate=0.2, max_depth=10, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = gb.predict(X_train)\n",
    "y_test_pred = gb.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "gb_train_score = r2_score(y_train, y_train_pred)\n",
    "gb_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "gb_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "gb_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "gb_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "gb_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "gb_train_rmse = np.sqrt(gb_train_mse)\n",
    "gb_test_rmse = np.sqrt(gb_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Gradient Boosting - Training R-squared: {gb_train_score}, Testing R-squared: {gb_test_score}\")\n",
    "print(f\"Gradient Boosting - Training MAE: {gb_train_mae}, Testing MAE: {gb_test_mae}\")\n",
    "print(f\"Gradient Boosting - Training MSE: {gb_train_mse}, Testing MSE: {gb_test_mse}\")\n",
    "print(f\"Gradient Boosting - Training RMSE: {gb_train_rmse}, Testing RMSE: {gb_test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree:\n",
    "not very good but only for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Training R-squared: 0.9964839344728202, Testing R-squared: 0.9697373468833944\n",
      "Decision Tree - Training MAE: 1443.9063410370945, Testing MAE: 4889.498446601941\n",
      "Decision Tree - Training MSE: 24139697.164453454, Testing MSE: 213715251.35545036\n",
      "Decision Tree - Training RMSE: 4913.216580251013, Testing RMSE: 14619.003090342732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "dt_train_score = r2_score(y_train, y_train_pred)\n",
    "dt_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "dt_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "dt_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "dt_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "dt_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "dt_train_rmse = np.sqrt(dt_train_mse)\n",
    "dt_test_rmse = np.sqrt(dt_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Decision Tree - Training R-squared: {dt_train_score}, Testing R-squared: {dt_test_score}\")\n",
    "print(f\"Decision Tree - Training MAE: {dt_train_mae}, Testing MAE: {dt_test_mae}\")\n",
    "print(f\"Decision Tree - Training MSE: {dt_train_mse}, Testing MSE: {dt_test_mse}\")\n",
    "print(f\"Decision Tree - Training RMSE: {dt_train_rmse}, Testing RMSE: {dt_test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "even though the k nearest neighbors are good for classification problem but here we use it as a benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors - Training R-squared: 0.9996322766703062, Testing R-squared: 0.5707533276549899\n",
      "K-Nearest Neighbors - Training MAE: 148.01914611251374, Testing MAE: 28856.69775204791\n",
      "K-Nearest Neighbors - Training MSE: 2524620.133070607, Testing MSE: 3031345603.4483376\n",
      "K-Nearest Neighbors - Training RMSE: 1588.9053253956345, Testing RMSE: 55057.65708281036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(algorithm= 'auto', n_neighbors=3, weights= 'distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "knn_train_score = r2_score(y_train, y_train_pred)\n",
    "knn_test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "knn_train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "knn_test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "knn_train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "knn_test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "knn_train_rmse = np.sqrt(knn_train_mse)\n",
    "knn_test_rmse = np.sqrt(knn_test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"K-Nearest Neighbors - Training R-squared: {knn_train_score}, Testing R-squared: {knn_test_score}\")\n",
    "print(f\"K-Nearest Neighbors - Training MAE: {knn_train_mae}, Testing MAE: {knn_test_mae}\")\n",
    "print(f\"K-Nearest Neighbors - Training MSE: {knn_train_mse}, Testing MSE: {knn_test_mse}\")\n",
    "print(f\"K-Nearest Neighbors - Training RMSE: {knn_train_rmse}, Testing RMSE: {knn_test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPRegressor - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Training R-squared: 0.7508395102526952, Testing R-squared: 0.7251055664532179\n",
      "Neural Network - Training MAE: 26761.140587159905, Testing MAE: 27885.675719750343\n",
      "Neural Network - Training MSE: 1710621921.392718, Testing MSE: 1941308078.1548567\n",
      "Neural Network - Training RMSE: 41359.665392659044, Testing RMSE: 44060.27778118128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(250), max_iter=1000, random_state=42)\n",
    "\n",
    "# nn_model = MLPRegressor(\n",
    "#     hidden_layer_sizes=(100,),  # One hidden layer with 100 neurons\n",
    "#     activation='relu',          # 'relu' activation function\n",
    "# activation function introduces the non-linearity to learn complex features\n",
    "#     solver='adam',              # 'adam' solver for weight optimization\n",
    "# adam optimizer \n",
    "#     max_iter=500,               # Set the number of iterations (epochs)\n",
    "#     random_state=42             # Set the seed for reproducibility\n",
    "# )\n",
    "\n",
    "# Training the model\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_train_pred = nn_model.predict(X_train)\n",
    "y_test_pred = nn_model.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "# Printing the results\n",
    "print(f\"Neural Network - Training R-squared: {train_r2}, Testing R-squared: {test_r2}\")\n",
    "print(f\"Neural Network - Training MAE: {train_mae}, Testing MAE: {test_mae}\")\n",
    "print(f\"Neural Network - Training MSE: {train_mse}, Testing MSE: {test_mse}\")\n",
    "print(f\"Neural Network - Training RMSE: {train_rmse}, Testing RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
