{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning Hyperparameters in previous tried algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(estimator, param_grid, model_name, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    predictions = best_estimator.predict(X_te\n",
    "    \n",
    "    best_mae = -grid_search.best_score_  # neg_mean_absolute_error is returned negative by GridSearchCV\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} Best MAE: {best_mae}\")\n",
    "    print(f\"{model_name} Best MSE: {mse}\")\n",
    "    print(f\"{model_name} Best RMSE: {rmse}\")\n",
    "    print(f\"{model_name} Best R-squared: {r2}\")\n",
    "\n",
    "\n",
    "# Random Forest Grid Search\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "perform_grid_search(RandomForestRegressor(random_state=42), rf_params, 'Random Forest', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Gradient Boosting Grid Search\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "perform_grid_search(GradientBoostingRegressor(random_state=42), gb_params, 'Gradient Boosting', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Decision Tree Grid Search\n",
    "dt_params = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "perform_grid_search(DecisionTreeRegressor(random_state=42), dt_params, 'Decision Tree', X_train, y_train, X_test, y_test)\n",
    "\n",
    "# K-Nearest Neighbors Grid Search\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "perform_grid_search(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors', X_train, y_train, X_test, y_test)\n",
    "\n",
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,100)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search for MLPRegressor\n",
    "perform_grid_search(MLPRegressor(random_state=42), nn_params, 'Neural Network', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stopped the training because it was very resource demanding and I have only standard laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
